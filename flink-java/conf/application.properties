## 任务并行度
flink.env.parallelism=1
## 检查点扫描间隔时间（毫秒）
flink.env.checkpoint.interval=5000
## 检查点状态路径
flink.env.state.backend.fs.path=file:///opt/checkpoint/flink/sih
## 检查点超时时间。单位毫秒
flink.env.checkpoint.timeout=600000
## 最大并发执行的检查点的数量
flink.env.checkpoint.concurrent.max=1
## 检查点失败次数重启作业门限
flink.env.checkpoint.tolerable.failure.number=3
## 水位线间隔时间
watermark.interval,seconds=7200

## Flink 自定义函数注册
flink.udf.to_char=org.luna.learn.flink.udfs.ToChar
flink.udf.to_date=org.luna.learn.flink.udfs.ToDate
flink.udf.to_timestamp=org.luna.learn.flink.udfs.ToTimestamp
flink.udf.date_format=org.luna.learn.flink.udfs.DateFormat
flink.udf.days=org.luna.learn.flink.udfs.Days
flink.udf.length=org.luna.learn.flink.udfs.Length


## SQL 脚本中可以使用 ${} 来引用变量
## 常用变量有以下几种：
##    1. ${curDate} -- 当前日期（yyyyMMdd）
## FlinkSQL JDBC 相关配置
flink.datasource.jdbc.db2.driver=com.ibm.db2.jcc.DB2Driver
flink.datasource.jdbc.mysql.driver=com.mysql.cj.jdbc.Driver
flink.datasource.jdbc.db2.buff.url=jdbc:db2://10.86.9.102:50001/buff
flink.datasource.jdbc.db2.buff.username=sih
flink.datasource.jdbc.db2.buff.password=SIHbuffpwd
flink.datasource.jdbc.db2.dw.url=jdbc:db2://10.86.9.101:50000/dw
flink.datasource.jdbc.db2.dw.username=sih
flink.datasource.jdbc.db2.dw.password=SIHdw123
flink.datasource.jdbc.mysql.sih.url=jdbc:mysql://localhost:3306/sih
flink.datasource.jdbc.mysql.sih.username=root
flink.datasource.jdbc.mysql.sih.password=root
## FlinkSQL Redis 数据源相关配置
## 自定义函数 getRedisDimensionCode 使默认使用该配置
flink.datasource.redis.sih.mode=single
flink.datasource.redis.sih.host=localhost
flink.datasource.redis.sih.port=6379
## FlinkSQL Kafka 数据源相关配置
flink.datasource.kafka.sih.zookeepers=localhost:2181
flink.datasource.kafka.sih.bootstrap.servers=localhost:9092
flink.datasource.kafka.sih.group.id=test
flink.datasource.kafka.sih.security.protocol=SASL_PLAINTEXT
flink.datasource.kafka.sih.sasl.mechanism=PLAIN
flink.datasource.kafka.sih.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="admin" password="admin-secret";
flink.datasource.kafka.sih.scan.startup.mode=earliest-offset

## 执行任务列表，可以由逗号分隔多个任务
## 多个任务间按排序的选后顺序执行，但任务间是相互独立的互不影响的
flink.job.execute=task3

## 任务配置，flink.job.<task_name> 是前缀
## 目前可以识别
##     1.flink.job.<task_name>.sql.<id>
##     2.flink.job.<task_name>.sql-file.<id>
##     3.flink.job.<task_name>.cache.<profile>
##     4.flink.job.<task_name>.run.<profile>
## 其他配置需求待开发
## flink.job.<task_name>.sql.<id> 配置的优先级高于 flink.job.<task_name>.sql-file.<id>
## 任务会优先执行 flink.job.<task_name>.sql.<id> 配置，然后再执行 flink.job.<task_name>.sql-file.<id>
## 在无特殊要求的情况下，推荐使用 flink.job.<task_name>.sql-file.<id> 配置
## 为保证执行的先后顺序，<id> 必须为数字型
## 任务运行模式 flink.job.<task_name>.run.mode
##    1.standalone -- 独立执行。任务内每个子任务间相互不影响(即后一个任务不依赖前一个任务的结果)
##    2.chain -- 链式执行。任务内每个子任务间按顺序依赖执行(即后一个任务依赖前一个任务的结果)
flink.job.task1.run.mode=chain
flink.job.task1.run.policy=parallel
flink.job.task1.run.waiting.interval=100
flink.job.task1.run.waiting.timeout=10000
flink.job.task1.sql-file.0=sql/test_step0_sync_src.sql

flink.job.task2.run.mode=standalone
flink.job.task2.run.policy=parallel
flink.job.task2.run.waiting.interval=100
flink.job.task2.run.waiting.timeout=10000
flink.job.task2.sql-file.1=sql/test_step1_src.sql
flink.job.task2.sql-file.2=sql/test_step2_src.sql

flink.job.task3.run.mode=standalone
flink.job.task3.run.policy=serial
flink.job.task3.run.waiting.interval=100
flink.job.task3.run.waiting.timeout=10000
# flink.job.task3.sql-file.0=sql/fact/REDIS.DW.VEHICLE_SALES_DF.sql
# flink.job.task3.sql-file.1=sql/fact/REDIS.DW.VEHICLE_INVOICE_DF.sql
# flink.job.task3.sql-file.1=sql/kafka/SAP.VLCVEHICLE.db2-kafka.sql
# flink.job.task3.sql-file.1=sql/kafka/SAP.VBAP.db2-kafka.sql
flink.job.task3.sql-file.1=sql/test.sql


